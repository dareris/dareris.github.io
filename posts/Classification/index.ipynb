{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Classification\"\n",
        "author: \"Rishav Khatiwada\"\n",
        "date: \"2023-11-19\"\n",
        "categories: [news, code, analysis]\n",
        "image: \"image.jpg\"\n",
        "---"
      ],
      "id": "4e197732"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we start with importing some of the required libraries\n"
      ],
      "id": "bfc540c9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as pl\n",
        "import seaborn as sns\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve\n",
        "from scipy.stats import ttest_ind"
      ],
      "id": "f7053bc3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Importing the data set\n"
      ],
      "id": "2438ca17"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_csv(\"Blacksburg_weather_dataset.csv\", index_col=\"DATE\")\n",
        "df.head()"
      ],
      "id": "795f9ae1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To make the data machine learning ready, we first identify the missing values, for that\n"
      ],
      "id": "a8acaaec"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.apply(pd.isnull).sum()/df.shape[0]"
      ],
      "id": "8daddfc4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's only take some of the features that we may need and let's convert them into columns\n"
      ],
      "id": "510dd765"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bb_weather= df[[\"PRCP\", \"SNOW\", \"TMAX\", \"TMIN\"]].copy()\n",
        "\n",
        "bb_weather.columns = [\"rain\", \"snow\", \"max_T\", \"min_T\"]\n",
        "\n",
        "bb_weather.head()"
      ],
      "id": "e10567dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bb_weather.apply(pd.isnull).sum()/bb_weather.shape[0]"
      ],
      "id": "44e81432",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's find out how many days there were rain in Blacksburg in the data set\n"
      ],
      "id": "53a1ff96"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bb_weather[\"rain\"].value_counts()"
      ],
      "id": "500024fa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since we are only concerned about the rainfall in Blacksburg and not the snowfall, let's delete snowfall column\n"
      ],
      "id": "87aacc24"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "del bb_weather['snow']"
      ],
      "id": "9842fe8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's fill all the days which has rainfall values missing as 0. Here, we can also delete the concerned rows but here we are using 0 as the replacement.\n"
      ],
      "id": "ac9b9757"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bb_weather[\"rain\"] = bb_weather[\"rain\"].fillna(0)"
      ],
      "id": "f003114a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bb_weather.apply(pd.isnull).sum()"
      ],
      "id": "9df4ecef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the weather of following day is mostly similar to the previous day we use forward fill in this case unlike rainfall\n"
      ],
      "id": "c0073d9d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bb_weather = bb_weather.fillna(method=\"ffill\")"
      ],
      "id": "ab7714c8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "documentation of this file says if any item has 9999 then this is the missing values, so to identify them we have this\n"
      ],
      "id": "6b18447a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bb_weather.apply(lambda x: (x == 9999).sum())"
      ],
      "id": "776744f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bb_weather.index = pd.to_datetime(bb_weather.index)"
      ],
      "id": "905a8274",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "let's visualize the rainfall in different years.\n"
      ],
      "id": "21e60074"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pl.plot(bb_weather['rain'],color='blue',marker='o')\n",
        "pl.xlabel('Year')\n",
        "pl.ylabel('Rainfall(cm)')"
      ],
      "id": "29ef76a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's create a new weather column based on the condition as rainy and non-rainy days.\n"
      ],
      "id": "7c2ac215"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bb_weather['weather'] = 'not_rainy'\n",
        "\n",
        "bb_weather.loc[bb_weather['rain'] > 0, 'weather'] = 'rainy'\n",
        "\n",
        "print(bb_weather)"
      ],
      "id": "8cd068f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since, it is difficult to deal with the words like rainy and non-rainy to perform our classification, we use one-hot encoding method to convert them into binary numbers as 1 and 0, where 1 represents rainy days.\n"
      ],
      "id": "e4a9b764"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "weather_encoded = pd.get_dummies(bb_weather['weather'], prefix='weather')\n",
        "\n",
        "bb_weather_encoded = pd.concat([bb_weather, weather_encoded], axis=1)\n",
        "\n",
        "\n",
        "bb_weather_encoded.drop('weather', axis=1, inplace=True)\n",
        "\n",
        "print(bb_weather_encoded)"
      ],
      "id": "91f13a76",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since we may get some of our values as negative also as the temperature might fall below 0 during winter, we convert our temperature in Farenheit to Kelvin using relation\n",
        "\n",
        "$(T-32)*5/9 + 273.15$\n"
      ],
      "id": "4a25b139"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bb_weather_encoded['min_T(Kelvin)'] = (bb_weather_encoded['min_T'] - 32) * 5/9 + 273.15\n",
        "bb_weather_encoded['max_T(Kelvin)'] = (bb_weather_encoded['max_T'] - 32) * 5/9 + 273.15"
      ],
      "id": "462d3e74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bb_weather_encoded.tail()"
      ],
      "id": "77ff0699",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For simplified operation, we also need to convert the rain column into binary not only the weather column.\n"
      ],
      "id": "a3e08226"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rainfall = pd.DataFrame(bb_weather_encoded)\n",
        "\n",
        "rainfall['rain'] = (rainfall['rain'] > 0).astype(int)"
      ],
      "id": "49824650",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To make maximum temperature and the minimum temperatures as our main features, let's use chi-squared test and select K best features.\n"
      ],
      "id": "8ca72a55"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = rainfall[['max_T(Kelvin)','min_T(Kelvin)']]\n",
        "y = rainfall['rain']\n",
        "\n",
        "k_best = SelectKBest(score_func=chi2, k=2)\n",
        "\n",
        "X_new = k_best.fit_transform(X, y)\n",
        "\n",
        "selected_feature_indices = k_best.get_support(indices=True)\n",
        "\n",
        "selected_features = X.columns[selected_feature_indices]\n",
        "\n",
        "print(\"Selected features:\", selected_features)"
      ],
      "id": "7676dad7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the classification of our data, we use the random forest classifier. By using this we find the classification report in the form of confusion matrix visualization.\n",
        "\n",
        "For that let's separate our data in terms of train and test part.\n"
      ],
      "id": "ffdaef1b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "start_date_train = '2000-01-01'\n",
        "end_date_train = '2017-12-31'\n",
        "start_date_test = '2018-01-01'\n",
        "end_date_test = '2023-10-05'"
      ],
      "id": "6cda35a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we then create the mask fo the data ranges and extract the data for train and test and finally apply the random forest classifier.\n"
      ],
      "id": "03916a71"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_train = (X.index >= start_date_train) & (X.index <= end_date_train)\n",
        "mask_test = (X.index >= start_date_test) & (X.index <= end_date_test)\n",
        "\n",
        "\n",
        "X_train, y_train = X[mask_train], y[mask_train]\n",
        "X_test, y_test = X[mask_test], y[mask_test]\n",
        "\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = rf_classifier.predict(X_test)"
      ],
      "id": "7b24e9b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next is finding the classification report and the visualization in confusion matrix.\n"
      ],
      "id": "1c1a7715"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "report = classification_report(y_test, y_pred)\n",
        "print('Classification Report:\\n', report)\n",
        "\n",
        "\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "print('Confusion Matrix:\\n', confusion)\n",
        "\n",
        "\n",
        "pl.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion, annot=True, fmt='d', cmap='Oranges', xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
        "pl.xlabel('Predicted')\n",
        "pl.ylabel('Actual')\n",
        "pl.title('Confusion Matrix')\n",
        "pl.show()"
      ],
      "id": "c28de00b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now to see if we can improve our results we perform feature importance.\n"
      ],
      "id": "003a0ae6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "feature_importance = rf_classifier.feature_importances_\n",
        "\n",
        "\n",
        "feature_names = ['max_T(Kelvin)','min_T(Kelvin)']\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
        "\n",
        "\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "\n",
        "pl.figure(figsize=(10, 6))\n",
        "pl.bar(importance_df['Feature'], importance_df['Importance'])\n",
        "pl.xticks(rotation=45)\n",
        "pl.title('Feature Importance for Snowfall Classification')\n",
        "pl.show()"
      ],
      "id": "c20dfdb7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we define the hyper parameters and their possible values:\n",
        "\n",
        "Here, we define the no. of trees in the forest(random forest classifier forest not the forest in nature), its max depth and we define the minimum samples to split internal node.\n"
      ],
      "id": "ac1d8954"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    \n",
        "    'max_depth': [None, 10, 20],\n",
        "    \n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    \n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    }\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy')  \n",
        "\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(\"Best Hyperparameters:\")\n",
        "print(best_params)\n",
        "\n",
        "\n",
        "results = pd.DataFrame(grid_search.cv_results_)"
      ],
      "id": "d8b4fdd2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And for the pivot table and confusion matrix visualization\n"
      ],
      "id": "00b7f9e6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pivot_table = results.pivot_table(index=['param_n_estimators', 'param_max_depth'],\n",
        "                                  columns='param_min_samples_split',\n",
        "                                  values='mean_test_score')\n",
        "\n",
        "\n",
        "pl.figure(figsize=(10, 6))\n",
        "sns.heatmap(pivot_table, annot=True, fmt=\".3f\", cmap=\"YlGnBu\")\n",
        "pl.title(\"Grid Search Results for Hyperparameters\")\n",
        "pl.xlabel(\"min_samples_split\")\n",
        "pl.ylabel(\"n_estimators / max_depth\")\n",
        "pl.show()"
      ],
      "id": "c85834ea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To identify, how accurate is the result that we obtained\n"
      ],
      "id": "de30c7be"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "final_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "final_model.fit(X, y)\n",
        "\n",
        "y_pred = final_model.predict(X)\n",
        "\n",
        "\n",
        "final_accuracy = accuracy_score(y, y_pred)\n",
        "\n",
        "print(f\"Final Model Accuracy: {final_accuracy:.2f}\")\n"
      ],
      "id": "45fbc16a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And hence following the same steps that we did earlier, we get new classification results.\n"
      ],
      "id": "4bec3eb0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "report1 = classification_report(y, y_pred)\n",
        "print('Classification Report:\\n', report1)"
      ],
      "id": "32fd44b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "confusion = confusion_matrix(y, y_pred)\n",
        "\n",
        "# Create a heatmap of the confusion matrix\n",
        "pl.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, xticklabels=True, yticklabels=True)\n",
        "pl.xlabel('Predicted')\n",
        "pl.ylabel('Actual')\n",
        "pl.title('Confusion Matrix')\n",
        "pl.show()"
      ],
      "id": "02354dc4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now to examine the Random Forest Model's performance, we first make ROC and Precision-Recall curves.\n",
        "\n",
        "It also help us identify the trade offs involved in different threshold settings.\n"
      ],
      "id": "a6605406"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "fpr, tpr, thresholds_roc = roc_curve(y_test, y_prob)\n",
        "\n",
        "auc_roc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_prob)"
      ],
      "id": "ee19ffaf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And to visualize:\n"
      ],
      "id": "96702acc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pl.figure(figsize=(12, 6))\n",
        "\n",
        "# Plotting ROC curve:\n",
        "pl.subplot(1, 2, 1)\n",
        "pl.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_roc:.2f})')\n",
        "pl.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "pl.xlabel('False Positive Rate')\n",
        "pl.ylabel('True Positive Rate')\n",
        "pl.title('ROC Curve')\n",
        "pl.legend()\n",
        "\n",
        "# Plotting PR curve:\n",
        "pl.subplot(1, 2, 2)\n",
        "pl.plot(recall, precision, label='Precision-Recall Curve')\n",
        "pl.xlabel('Recall')\n",
        "pl.ylabel('Precision')\n",
        "pl.title('Precision-Recall Curve')\n",
        "pl.legend()\n",
        "\n",
        "# Adjusting the layout to prevent overlap of subplots\n",
        "pl.tight_layout()"
      ],
      "id": "9ce1e74b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pl.subplot(2, 1, 1)\n",
        "sns.boxplot(data=df, y='min_T(Kelvin)', x='rain')\n",
        "pl.title('Min Temperature vs. Rainfall')\n",
        "pl.figure(figsize=(4, 3))\n",
        "\n",
        "\n",
        "pl.subplot(2, 1, 2)\n",
        "sns.boxplot(data=df, x='rain', y='max_T(Kelvin)')\n",
        "pl.title('Max Temperature by Rain')\n",
        "pl.figure(figsize=(4, 3))\n",
        "pl.show()"
      ],
      "id": "0e042cf9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And Finally for the T-test results and the accuracy scores:\n"
      ],
      "id": "6ac490ea"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "t_stat, p_value = ttest_ind(max_temp_rain, max_temp_no_rain)\n",
        "print(f'T-Test Results (max_T(Kelvin)): t-statistic={t_stat:.2f}, p-value={p_value:.4f}')\n",
        "\n",
        "print(f'Model Accuracy: {final_accuracy:.2f}')"
      ],
      "id": "38de0e74",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the future, if we want to know the accuracy of any dataframe directly we can use the following code to directly give the accuracy score once we upload a file which has been cleaned to make ML ready.\n",
        "\n",
        "\"\n",
        "\n",
        "# Accuracy score Prediction\n",
        "\n",
        "#Load the trained ML model\n",
        "\n",
        "model = joblib.load(\"filename\") \\# Replace with the path to your model file\n",
        "\n",
        "def predict_snowfall(min_temp, max_temp): try:\n",
        "\n",
        "\\# Create a DataFrame with the input data\n",
        "\n",
        "input_data = pd.DataFrame({'min_T(Kelvin)': \\[min_temp\\], 'max_T(Kelvin)': \\[max_temp\\]})\n",
        "\n",
        "```         \n",
        "    # Make predictions\n",
        "    prediction = model.predict(input_data)\n",
        "\n",
        "    return prediction[0]\n",
        "except Exception as e:\n",
        "    return str(e)\n",
        "```\n",
        "\n",
        "if **name** == '**main**': print(\"Temperature to rainfall Prediction\")\n",
        "\n",
        "min_temp = float(input(\"Enter Minimum Temperature (Kelvin):\"))\n",
        "\n",
        "max_temp = float(input(\"Enter Maximum Temperature (Kelvin):\"))\n",
        "\n",
        "```         \n",
        "result = predict_rainfall(min_temp, max_temp)\n",
        "print(f\"rainfall Prediction: {result}\")\n",
        "```\n",
        "\n",
        "\""
      ],
      "id": "1ee3773e"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}