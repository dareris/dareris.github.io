{
  "hash": "d518068e8930b1afe0f661d0bf550d84",
  "result": {
    "markdown": "---\ntitle: \"Anomaly Detection\"\nauthor: \"Rishav Khatiwada\"\ndate: \"2023-11-19\"\ncategories: [news, code, analysis]\nimage: \"image1.jpg\"\n---\n\nImporting the required libraries:\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as pl\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.metrics import silhouette_score, silhouette_samples\nfrom sklearn.decomposition import PCA\n```\n:::\n\n\nimporting the dataset:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndata=pd.read_csv('kalimati_tarkari_dataset.csv',index_col='SN')\ndata.head\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n<bound method NDFrame.head of                   Commodity        Date Unit  Minimum  Maximum  Average\nSN                                                                     \n0        Tomato Big(Nepali)  2013-06-16   Kg     35.0     40.0     37.5\n1       Tomato Small(Local)  2013-06-16   Kg     26.0     32.0     29.0\n2                Potato Red  2013-06-16   Kg     20.0     21.0     20.5\n3              Potato White  2013-06-16   Kg     15.0     16.0     15.5\n4        Onion Dry (Indian)  2013-06-16   Kg     28.0     30.0     29.0\n...                     ...         ...  ...      ...      ...      ...\n197156    Garlic Dry Nepali  2021-05-13   Kg    100.0    120.0    110.0\n197157     Fish Fresh(Rahu)  2021-05-13   KG    270.0    280.0    275.0\n197158  Fish Fresh(Bachuwa)  2021-05-13   KG    225.0    235.0    230.0\n197159   Fish Fresh(Chhadi)  2021-05-13   KG    220.0    230.0    225.0\n197160  Fish Fresh(Mungari)  2021-05-13   KG    240.0    250.0    245.0\n\n[197161 rows x 6 columns]>\n```\n:::\n:::\n\n\nOnly selecting the data January 1st 2020 onward which we are interested in:\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nspecific_date_1 = pd.to_datetime('2020-01-01') \ndata['Date'] = pd.to_datetime(data['Date'])\nspecific_date = pd.to_datetime(specific_date_1)\ndata = data[data['Date'] > specific_date]\ndata\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Commodity</th>\n      <th>Date</th>\n      <th>Unit</th>\n      <th>Minimum</th>\n      <th>Maximum</th>\n      <th>Average</th>\n    </tr>\n    <tr>\n      <th>SN</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>157524</th>\n      <td>Tomato Big(Nepali)</td>\n      <td>2020-01-02</td>\n      <td>Kg</td>\n      <td>65.0</td>\n      <td>70.0</td>\n      <td>67.5</td>\n    </tr>\n    <tr>\n      <th>157525</th>\n      <td>Tomato Big(Indian)</td>\n      <td>2020-01-02</td>\n      <td>Kg</td>\n      <td>65.0</td>\n      <td>70.0</td>\n      <td>67.5</td>\n    </tr>\n    <tr>\n      <th>157526</th>\n      <td>Tomato Small(Local)</td>\n      <td>2020-01-02</td>\n      <td>Kg</td>\n      <td>40.0</td>\n      <td>50.0</td>\n      <td>45.0</td>\n    </tr>\n    <tr>\n      <th>157527</th>\n      <td>Tomato Small(Tunnel)</td>\n      <td>2020-01-02</td>\n      <td>Kg</td>\n      <td>40.0</td>\n      <td>50.0</td>\n      <td>45.0</td>\n    </tr>\n    <tr>\n      <th>157528</th>\n      <td>Tomato Small(Indian)</td>\n      <td>2020-01-02</td>\n      <td>KG</td>\n      <td>40.0</td>\n      <td>50.0</td>\n      <td>45.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>197156</th>\n      <td>Garlic Dry Nepali</td>\n      <td>2021-05-13</td>\n      <td>Kg</td>\n      <td>100.0</td>\n      <td>120.0</td>\n      <td>110.0</td>\n    </tr>\n    <tr>\n      <th>197157</th>\n      <td>Fish Fresh(Rahu)</td>\n      <td>2021-05-13</td>\n      <td>KG</td>\n      <td>270.0</td>\n      <td>280.0</td>\n      <td>275.0</td>\n    </tr>\n    <tr>\n      <th>197158</th>\n      <td>Fish Fresh(Bachuwa)</td>\n      <td>2021-05-13</td>\n      <td>KG</td>\n      <td>225.0</td>\n      <td>235.0</td>\n      <td>230.0</td>\n    </tr>\n    <tr>\n      <th>197159</th>\n      <td>Fish Fresh(Chhadi)</td>\n      <td>2021-05-13</td>\n      <td>KG</td>\n      <td>220.0</td>\n      <td>230.0</td>\n      <td>225.0</td>\n    </tr>\n    <tr>\n      <th>197160</th>\n      <td>Fish Fresh(Mungari)</td>\n      <td>2021-05-13</td>\n      <td>KG</td>\n      <td>240.0</td>\n      <td>250.0</td>\n      <td>245.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>39637 rows Ã— 6 columns</p>\n</div>\n```\n:::\n:::\n\n\nSaving the commodity and date columns in its original form so that it can be used later as we will be converting them using label encoder.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nCommodity = data['Commodity'].tolist()\nDate = data['Date'].tolist()\n```\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\npl.scatter(data.iloc[:,3],data.iloc[:,4])\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n<matplotlib.collections.PathCollection at 0x224a2581810>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-2.png){width=583 height=411}\n:::\n:::\n\n\nIdentifying the missing values:\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndata.apply(pd.isnull).sum()/data.shape[0]\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nCommodity    0.0\nDate         0.0\nUnit         0.0\nMinimum      0.0\nMaximum      0.0\nAverage      0.0\ndtype: float64\n```\n:::\n:::\n\n\nDescribing the data to know the details of our features:\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndata.describe()\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Minimum</th>\n      <th>Maximum</th>\n      <th>Average</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>39637</td>\n      <td>39637.000000</td>\n      <td>39637.000000</td>\n      <td>39637.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2020-09-27 03:02:53.020158208</td>\n      <td>100.141787</td>\n      <td>110.051518</td>\n      <td>105.096652</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2020-01-02 00:00:00</td>\n      <td>6.000000</td>\n      <td>8.000000</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2020-05-25 00:00:00</td>\n      <td>40.000000</td>\n      <td>50.000000</td>\n      <td>45.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2020-10-19 00:00:00</td>\n      <td>70.000000</td>\n      <td>80.000000</td>\n      <td>75.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2021-02-02 00:00:00</td>\n      <td>120.000000</td>\n      <td>130.000000</td>\n      <td>125.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2021-05-13 00:00:00</td>\n      <td>1800.000000</td>\n      <td>2000.000000</td>\n      <td>1900.000000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>92.813213</td>\n      <td>97.867785</td>\n      <td>95.277303</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nsns.distplot(data[\"Average\"])\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\poude\\AppData\\Local\\Temp\\ipykernel_19400\\1442402836.py:1: UserWarning: \n\n`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n\nPlease adapt your code to use either `displot` (a figure-level function with\nsimilar flexibility) or `histplot` (an axes-level function for histograms).\n\nFor a guide to updating your code to use the new functions, please see\nhttps://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n\n  sns.distplot(data[\"Average\"])\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\n<Axes: xlabel='Average', ylabel='Density'>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-3.png){width=615 height=429}\n:::\n:::\n\n\nFrom this we can see that the data is right skewed.\n\nTo perform the anomaly detection we can use different models. Here, we will discuss some of the models but eventually we will be using DBSCAN.\n\nFirst, we test the z_score to find anomaly.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nprice = ['Minimum', 'Maximum', 'Average']\n\nz_scores = stats.zscore(data[price])\n\nthreshold = 2\n\nanamoly1 = data[(z_scores > threshold).any(axis=1)]\nprint(anamoly1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               Commodity       Date Unit  Minimum  Maximum  Average\nSN                                                                 \n157571  Mushroom(Button) 2020-01-02   KG    330.0    340.0    335.0\n157598        Chilli Dry 2020-01-02   Kg    390.0    400.0    395.0\n157657  Mushroom(Button) 2020-01-03   KG    340.0    350.0    345.0\n157684        Chilli Dry 2020-01-03   Kg    390.0    400.0    395.0\n157742  Mushroom(Button) 2020-01-04   KG    320.0    330.0    325.0\n...                  ...        ...  ...      ...      ...      ...\n197054        Strawberry 2021-05-12   Kg    400.0    500.0    450.0\n197056        Chilli Dry 2021-05-12   Kg    320.0    330.0    325.0\n197114         Asparagus 2021-05-13   Kg   1000.0   1050.0   1025.0\n197145        Strawberry 2021-05-13   Kg    450.0    500.0    475.0\n197147        Chilli Dry 2021-05-13   Kg    320.0    330.0    325.0\n\n[2208 rows x 6 columns]\n```\n:::\n:::\n\n\nSecond, we use interquartile range(IQR) for anomaly detection.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nQ1 = data[price].quantile(0.25)\nQ3 = data[price].quantile(0.75)\nIQR = Q3 - Q1\n\n\nthreshold = 1.5\n\n\nanamoly2 = data[((data[price] < (Q1 - threshold * IQR)) | (data[price] > (Q3 + threshold * IQR))).any(axis=1)]\n\nprint(anamoly2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               Commodity       Date Unit  Minimum  Maximum  Average\nSN                                                                 \n157571  Mushroom(Button) 2020-01-02   KG    330.0    340.0    335.0\n157575            Celery 2020-01-02   Kg    270.0    280.0    275.0\n157576          Parseley 2020-01-02   Kg    270.0    280.0    275.0\n157578              Mint 2020-01-02   Kg    270.0    280.0    275.0\n157583           Gundruk 2020-01-02   Kg    280.0    290.0    285.0\n...                  ...        ...  ...      ...      ...      ...\n197130       Pomegranate 2021-05-13   Kg    280.0    300.0    290.0\n197141     Pear(Chinese) 2021-05-13   Kg    250.0    260.0    255.0\n197145        Strawberry 2021-05-13   Kg    450.0    500.0    475.0\n197147        Chilli Dry 2021-05-13   Kg    320.0    330.0    325.0\n197157  Fish Fresh(Rahu) 2021-05-13   KG    270.0    280.0    275.0\n\n[4039 rows x 6 columns]\n```\n:::\n:::\n\n\nSelecting the numerical features of which we want to detect anomalies:\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nprice = ['Minimum', 'Maximum', 'Average']\n\n\nmodel = IsolationForest(contamination=0.05)\n\nmodel.fit(data[price])\n\nanomaly = model.predict(data[price])\nanomaly\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\narray([1, 1, 1, ..., 1, 1, 1])\n```\n:::\n:::\n\n\nAnd performing the element-wise comparison\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nprice = np.where(anomaly < 0)\nprice\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n(array([   47,    74,   133, ..., 39590, 39621, 39623], dtype=int64),)\n```\n:::\n:::\n\n\nMaking our earlier scatter plot more beautiful:\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nnew_price=data.values\npl.scatter(data.iloc[:,3],data.iloc[:,4])\npl.scatter(new_price[price,3],new_price[price,4],edgecolor='blue')\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n<matplotlib.collections.PathCollection at 0x224a9883710>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-14-output-2.png){width=583 height=411}\n:::\n:::\n\n\nConverting our Date features to a numerical format and converting that timestamp into an integer:\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ndata[\"Date\"] = pd.to_datetime(data[\"Date\"]).apply(lambda x: x.timestamp())\n\ndata[\"Date\"] = data[\"Date\"].astype(int)\n\ndata.head()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\poude\\AppData\\Local\\Temp\\ipykernel_19400\\2041701408.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[\"Date\"] = pd.to_datetime(data[\"Date\"]).apply(lambda x: x.timestamp())\nC:\\Users\\poude\\AppData\\Local\\Temp\\ipykernel_19400\\2041701408.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data[\"Date\"] = data[\"Date\"].astype(int)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Commodity</th>\n      <th>Date</th>\n      <th>Unit</th>\n      <th>Minimum</th>\n      <th>Maximum</th>\n      <th>Average</th>\n    </tr>\n    <tr>\n      <th>SN</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>157524</th>\n      <td>Tomato Big(Nepali)</td>\n      <td>1577923200</td>\n      <td>Kg</td>\n      <td>65.0</td>\n      <td>70.0</td>\n      <td>67.5</td>\n    </tr>\n    <tr>\n      <th>157525</th>\n      <td>Tomato Big(Indian)</td>\n      <td>1577923200</td>\n      <td>Kg</td>\n      <td>65.0</td>\n      <td>70.0</td>\n      <td>67.5</td>\n    </tr>\n    <tr>\n      <th>157526</th>\n      <td>Tomato Small(Local)</td>\n      <td>1577923200</td>\n      <td>Kg</td>\n      <td>40.0</td>\n      <td>50.0</td>\n      <td>45.0</td>\n    </tr>\n    <tr>\n      <th>157527</th>\n      <td>Tomato Small(Tunnel)</td>\n      <td>1577923200</td>\n      <td>Kg</td>\n      <td>40.0</td>\n      <td>50.0</td>\n      <td>45.0</td>\n    </tr>\n    <tr>\n      <th>157528</th>\n      <td>Tomato Small(Indian)</td>\n      <td>1577923200</td>\n      <td>KG</td>\n      <td>40.0</td>\n      <td>50.0</td>\n      <td>45.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nTO maintain the consistency, we choose to use standard scalar to scale our data:\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\ndata = data.drop(\"Commodity\",axis=1)\ndata = data.drop(\"Unit\",axis=1)\n\nscaler = StandardScaler()\ndata = scaler.fit_transform(data)\n```\n:::\n\n\nReducing the dimensions of our data to 2 using PCA:\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nnum_components = 2\npca = PCA(n_components=num_components)\n\ndata = pca.fit_transform(data)\ndata\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\narray([[-0.79822404,  1.77395273],\n       [-0.79822404,  1.77395273],\n       [-1.20721222,  1.74699569],\n       ...,\n       [ 2.36499445, -1.39243537],\n       [ 2.27428372, -1.39829777],\n       [ 2.63712665, -1.37484816]])\n```\n:::\n:::\n\n\nPerforming the DBSCAN clustering using PCA component 1 and 2 each representing one dimension.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\neps = 0.6\nmin_samples = 10\n\ndbscan = DBSCAN(eps=eps, min_samples=min_samples)\ndbscan.fit(data)\n\n\npl.figure(figsize=(10, 6))\nsns.scatterplot(x=data[:, 0], y=data[:, 1], hue=dbscan.labels_, palette='viridis', legend='full')\n\n\nanomaly_mask = dbscan.labels_ == -1\nsns.scatterplot(x=data[anomaly_mask, 0], y=data[anomaly_mask, 1], color='red', marker='x', label='Anomalies')\n\npl.title(\"DBSCAN Clustering with Anomalies (PCA-transformed)\")\npl.xlabel(\"PCA Component 1\")\npl.ylabel(\"PCA Component 2\")\npl.legend()\npl.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-18-output-1.png){width=823 height=523}\n:::\n:::\n\n\nTo see the performance of our Clustering model, we use Silhouette Score:\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nsilhouette_avg = silhouette_score(data, dbscan.labels_)\nprint(f\"Silhouette Score: {silhouette_avg}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSilhouette Score: 0.8130632448850426\n```\n:::\n:::\n\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\ncluster_labels = dbscan.fit_predict(data)\n\ndata = pd.DataFrame({'x': data[:, 0], 'y': data[:, 1], 'cluster': cluster_labels, 'Date': Date,\"Commodity\":Commodity})\n\ndata\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>cluster</th>\n      <th>Date</th>\n      <th>Commodity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.798224</td>\n      <td>1.773953</td>\n      <td>0</td>\n      <td>2020-01-02</td>\n      <td>Tomato Big(Nepali)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.798224</td>\n      <td>1.773953</td>\n      <td>0</td>\n      <td>2020-01-02</td>\n      <td>Tomato Big(Indian)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.207212</td>\n      <td>1.746996</td>\n      <td>0</td>\n      <td>2020-01-02</td>\n      <td>Tomato Small(Local)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.207212</td>\n      <td>1.746996</td>\n      <td>0</td>\n      <td>2020-01-02</td>\n      <td>Tomato Small(Tunnel)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.207212</td>\n      <td>1.746996</td>\n      <td>0</td>\n      <td>2020-01-02</td>\n      <td>Tomato Small(Indian)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39632</th>\n      <td>0.186357</td>\n      <td>-1.534286</td>\n      <td>0</td>\n      <td>2021-05-13</td>\n      <td>Garlic Dry Nepali</td>\n    </tr>\n    <tr>\n      <th>39633</th>\n      <td>3.181391</td>\n      <td>-1.339674</td>\n      <td>0</td>\n      <td>2021-05-13</td>\n      <td>Fish Fresh(Rahu)</td>\n    </tr>\n    <tr>\n      <th>39634</th>\n      <td>2.364994</td>\n      <td>-1.392435</td>\n      <td>0</td>\n      <td>2021-05-13</td>\n      <td>Fish Fresh(Bachuwa)</td>\n    </tr>\n    <tr>\n      <th>39635</th>\n      <td>2.274284</td>\n      <td>-1.398298</td>\n      <td>0</td>\n      <td>2021-05-13</td>\n      <td>Fish Fresh(Chhadi)</td>\n    </tr>\n    <tr>\n      <th>39636</th>\n      <td>2.637127</td>\n      <td>-1.374848</td>\n      <td>0</td>\n      <td>2021-05-13</td>\n      <td>Fish Fresh(Mungari)</td>\n    </tr>\n  </tbody>\n</table>\n<p>39637 rows Ã— 5 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\npl.figure(figsize=(10, 6))\nax = sns.scatterplot(x=\"x\", y=\"y\", hue=\"cluster\", data=data, palette=\"viridis\", s=100)\n\n\nfor x, y, Date, cluster in zip(data['x'], data['y'], data['Date'], data['cluster']):\n    pl.text(x, y, Date, fontsize=10, alpha=0.8)\n\n\nax.set(ylim=(-3, 3))\npl.xlabel(\"Principal Component 1\", fontsize=15)\npl.ylabel(\"Principal Component 2\", fontsize=15)\n\n\npl.legend(title='Cluster', loc='upper right', labels=[f'Cluster {label}' for label in data['cluster'].unique()])\n\n\npl.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-21-output-1.png){width=925 height=515}\n:::\n:::\n\n\nIt is difficult to visualize individual data with so much compact cluster. So, let's try to do it the other way where we break our clusters and visualize only the one that is important to us.\n\nHere, these are the anomaly that we wanted to see.\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\ndata = data[data['cluster'] == -1]\n\nax = sns.scatterplot(x=\"x\", y=\"y\", data=data, color=\"red\", s=100)\n\n\nfor x, y, Commodity in zip(data['x'], data['y'], data['Commodity']):\n    pl.text(x, y, Commodity, fontsize=10, alpha=0.8)\n\n\nax.set(ylim=(-3, 3))\npl.xlabel(\"Principal Component 1\", fontsize=15)\npl.ylabel(\"Principal Component 2\", fontsize=15)\n\npl.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-22-output-1.png){width=641 height=441}\n:::\n:::\n\n\nLet's visualize it more clearly the other way:\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\ndata = data[data['cluster'] == -1]\n\npl.figure(figsize=(10, 6))\nsns.countplot(y='Commodity', data=data, color='green')\npl.xlabel(\"Count\", fontsize=15)\npl.ylabel(\"Commodity\", fontsize=15)\npl.title(\"Commodity Counts in Cluster -1\", fontsize=20)\npl.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-23-output-1.png){width=932 height=539}\n:::\n:::\n\n\nWe can see that the Vegetables like Asparagus and Mushroom, spice like Akbare Green Chilli, Fruits like Strawberry which are less consumed in Nepal and are usually more expensive than other vegetables see the anomalies in price. This is simply because people are usually unaware of their actual price as these foods are less consumed in Kathmandu and the whole sellers and retailers take an advantage of this and rise their price citing various reasons like weather, change in fuel price, etc. The suprising commodity that features in this list is Chinese Garlic, which is a popular and most sold spice in Kathmandu. The reason may be the sellers sometime increase the price by creating fake shortage of this product for more profit by saying there has been some problem during import as it is imported from China. This is not very uncommon thing there. So, the concerned authority should really need to pay attention to the sudden increase of the off seasonal and less consumed commodity in addition to the regular ones.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}